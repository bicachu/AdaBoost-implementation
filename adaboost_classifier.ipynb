{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  word_freq_make word_freq_address word_freq_all word_freq_3d word_freq_our  \\\n",
       "0           0.00              0.64          0.64          0.0          0.32   \n",
       "1           0.21              0.28          0.50          0.0          0.14   \n",
       "2           0.06              0.00          0.71          0.0          1.23   \n",
       "3           0.00              0.00          0.00          0.0          0.63   \n",
       "4           0.00              0.00          0.00          0.0          0.63   \n",
       "\n",
       "  word_freq_over word_freq_remove word_freq_internet word_freq_order  \\\n",
       "0           0.00             0.00               0.00            0.00   \n",
       "1           0.28             0.21               0.07            0.00   \n",
       "2           0.19             0.19               0.12            0.64   \n",
       "3           0.00             0.31               0.63            0.31   \n",
       "4           0.00             0.31               0.63            0.31   \n",
       "\n",
       "  word_freq_mail  ... char_freq_; char_freq_( char_freq_[ char_freq_!  \\\n",
       "0           0.00  ...        0.00       0.000         0.0       0.778   \n",
       "1           0.94  ...        0.00       0.132         0.0       0.372   \n",
       "2           0.25  ...        0.01       0.143         0.0       0.276   \n",
       "3           0.63  ...        0.00       0.137         0.0       0.137   \n",
       "4           0.63  ...        0.00       0.135         0.0       0.135   \n",
       "\n",
       "  char_freq_$ char_freq_# capital_run_length_average  \\\n",
       "0       0.000       0.000                      3.756   \n",
       "1       0.180       0.048                      5.114   \n",
       "2       0.184       0.010                      9.821   \n",
       "3       0.000       0.000                      3.537   \n",
       "4       0.000       0.000                      3.537   \n",
       "\n",
       "  capital_run_length_longest capital_run_length_total class  \n",
       "0                         61                      278     1  \n",
       "1                        101                     1028     1  \n",
       "2                        485                     2259     1  \n",
       "3                         40                      191     1  \n",
       "4                         40                      191     1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "# Supress Warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from random import randrange\n",
    "from sklearn import preprocessing, tree\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (mean_squared_error, r2_score, accuracy_score, precision_score,\n",
    "                             recall_score, f1_score)\n",
    "\n",
    "# Read in spam dataset into a pandas dataframe\n",
    "spamData = pd.read_csv('input/spambase.txt', header=None)\n",
    "with open('input/spambase_names.txt', 'r') as f:\n",
    "    names = list(csv.reader(f, delimiter=','))\n",
    "spamData.columns = names\n",
    "\n",
    "# Create feature and target class data set\n",
    "features = spamData.drop(['class'], axis=1)\n",
    "target = spamData[['class']]\n",
    "spamData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state = 0)\n",
    "\n",
    "# Standardize the x_train and x_test datasets\n",
    "std_scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = std_scaler.transform(X_train)\n",
    "X_test_scaled = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change predictions from {0,1} to {-1,1} in order to properly compute predictions\n",
    "y_test_new = np.where(y_test == 0, -1, 1)\n",
    "y_train_new = np.where(y_train == 0, -1, 1)\n",
    "\n",
    "# Class for AdaBoost implementation\n",
    "class AdaBoostCLF:\n",
    "\n",
    "    def __init__(self, X_train, y_train, T):\n",
    "        self.x_train = X_train\n",
    "        self.y_train = list(np.array(y_train).flatten())\n",
    "        self.T = T\n",
    "        self.N = len(self.x_train)\n",
    "        self.weights =  np.ones(self.N)/self.N\n",
    "        self.stumps = []  \n",
    "        self.alphas = []\n",
    "\n",
    "    def train(self):\n",
    "        for t in range(self.T):\n",
    "            dtc =  DecisionTreeClassifier(criterion = \"gini\", splitter = \"best\", max_depth = 1)\n",
    "            stump = dtc.fit(self.x_train, self.y_train, sample_weight = self.weights)\n",
    "            pred_train = dtc.predict(self.x_train)\n",
    "            \n",
    "            # Compute misclassified instances, errors, and alphas\n",
    "            incorrect = np.where(pred_train != self.y_train, 1, 0)\n",
    "            error = np.dot(self.weights, incorrect )/(self.weights).sum(dtype = 'float')\n",
    "            alpha_t = 0.5 * np.log((1 - error) / error)\n",
    "            \n",
    "            # Compute the corresponding pos/neg coeffs to allow for proper weight updates\n",
    "            weight_coeffs =  np.where(incorrect == 1 , 1, -1)\n",
    "            weights = np.multiply(self.weights, np.exp(alpha_t * weight_coeffs))\n",
    "            norm_weights = (weights/weights.sum(dtype = 'float'))\n",
    "            \n",
    "            # Update weights, stumps, and betas for current t iteration \n",
    "            self.weights = norm_weights\n",
    "            self.stumps.append(stump)\n",
    "            self.alphas.append(alpha_t)\n",
    "            \n",
    "    def computePredictions(self, X):\n",
    "            num_classifiers = self.T\n",
    "            num_records = len(X)\n",
    "            \n",
    "            # Initialize a list to hold the prediction* the corresponding alpha_t weights a*h(x) for each iteration\n",
    "            alpha_preds = np.zeros((num_records, num_classifiers))\n",
    "            \n",
    "            # Iterate through all classifiers and all given records and add prediction \n",
    "            for c in range(num_classifiers):\n",
    "                curr_clf = self.stumps[c] \n",
    "                curr_preds = curr_clf.predict(X)\n",
    "                for i in range(num_records):\n",
    "                    alpha_preds[i][c] = curr_preds[i] * self.alphas[c]\n",
    "            final_preds = []\n",
    "            \n",
    "            # Iterate through each record to compute hypothesis across all T classifiers\n",
    "            for tr in range(num_records):\n",
    "                if np.sign(sum(alpha_preds[tr])) <= 0:\n",
    "                    final_preds.append(-1)\n",
    "                else:\n",
    "                    final_preds.append(1)\n",
    "            return final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training</th>\n",
       "      <th>testing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1 decision stump</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>accuracy:</td>\n",
       "      <td>0.791884</td>\n",
       "      <td>0.789748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>error:</td>\n",
       "      <td>0.208116</td>\n",
       "      <td>0.210252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>precision:</td>\n",
       "      <td>0.717914</td>\n",
       "      <td>0.726141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>recall:</td>\n",
       "      <td>0.773097</td>\n",
       "      <td>0.76087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50 decision stumps</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>accuracy:</td>\n",
       "      <td>0.935072</td>\n",
       "      <td>0.922676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>error:</td>\n",
       "      <td>0.0649275</td>\n",
       "      <td>0.0773241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>precision:</td>\n",
       "      <td>0.935235</td>\n",
       "      <td>0.955774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>recall:</td>\n",
       "      <td>0.896526</td>\n",
       "      <td>0.845652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100 decision stumps</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>accuracy:</td>\n",
       "      <td>0.944928</td>\n",
       "      <td>0.925282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>error:</td>\n",
       "      <td>0.0550725</td>\n",
       "      <td>0.0747176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>precision:</td>\n",
       "      <td>0.942879</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>recall:</td>\n",
       "      <td>0.915004</td>\n",
       "      <td>0.86087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150 decision stumps</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>accuracy:</td>\n",
       "      <td>0.949275</td>\n",
       "      <td>0.936577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>error:</td>\n",
       "      <td>0.0507246</td>\n",
       "      <td>0.0634231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>precision:</td>\n",
       "      <td>0.947568</td>\n",
       "      <td>0.964029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>recall:</td>\n",
       "      <td>0.921656</td>\n",
       "      <td>0.873913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      training    testing\n",
       "1 decision stump                         \n",
       "accuracy:             0.791884   0.789748\n",
       "error:                0.208116   0.210252\n",
       "precision:            0.717914   0.726141\n",
       "recall:               0.773097    0.76087\n",
       "50 decision stumps                       \n",
       "accuracy:             0.935072   0.922676\n",
       "error:               0.0649275  0.0773241\n",
       "precision:            0.935235   0.955774\n",
       "recall:               0.896526   0.845652\n",
       "100 decision stumps                      \n",
       "accuracy:             0.944928   0.925282\n",
       "error:               0.0550725  0.0747176\n",
       "precision:            0.942879   0.947368\n",
       "recall:               0.915004    0.86087\n",
       "150 decision stumps                      \n",
       "accuracy:             0.949275   0.936577\n",
       "error:               0.0507246  0.0634231\n",
       "precision:            0.947568   0.964029\n",
       "recall:               0.921656   0.873913"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize different iteration values to try for T\n",
    "T_values = [1, 50, 100, 150]\n",
    "\n",
    "# Initialize lists to hold training and testing scores\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# Function to compute all scores itertatively across various T iterations\n",
    "def computeScores(X_train, y_train, X_test, y_test, T_values):\n",
    "    for i in range(0, len(T_values)):\n",
    "        clf = AdaBoostCLF(X_train, y_train, T_values[i])\n",
    "        clf.train()\n",
    "        preds_train = clf.computePredictions(X_train)\n",
    "        preds_test = clf.computePredictions(X_test)\n",
    "        acc_score_tr = accuracy_score(y_train,preds_train)\n",
    "        acc_score_tst = accuracy_score(y_test, preds_test)\n",
    "        err_score_tr = 1 - acc_score_tr\n",
    "        err_score_tst = 1 - acc_score_tst\n",
    "        precision_tr =  precision_score(y_train, preds_train, pos_label = 1)\n",
    "        precision_tst =  precision_score(y_test, preds_test, pos_label = 1)\n",
    "        recall_tr =  recall_score(y_train, preds_train, pos_label = 1)\n",
    "        recall_tst =  recall_score(y_test, preds_test, pos_label = 1)\n",
    "        train_scores.extend((\"\", acc_score_tr, err_score_tr, precision_tr, recall_tr))\n",
    "        test_scores.extend((\"\", acc_score_tst, err_score_tst, precision_tst, recall_tst))\n",
    "\n",
    "# Call the function to compute scores and populate lists\n",
    "computeScores(X_train_scaled, y_train_new, X_test_scaled, y_test_new, T_values)\n",
    "\n",
    "# Create dictionary of test/train metrics\n",
    "scores_dict = {'training' :train_scores, 'testing' : test_scores } \n",
    "\n",
    "# Convert all scores to dataframe\n",
    "scoresDF = pd.DataFrame.from_dict(scores_dict)\n",
    "row_names = ['1 decision stump', 'accuracy:', 'error:', 'precision:','recall:',\n",
    "             '50 decision stumps', 'accuracy:', 'error:', 'precision:','recall:',\n",
    "            '100 decision stumps', 'accuracy:', 'error:', 'precision:','recall:',\n",
    "            '150 decision stumps', 'accuracy:', 'error:', 'precision:','recall:']\n",
    "\n",
    "scoresDF.index = row_names\n",
    "scoresDF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
